{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "khasCDTIrKtB",
    "ExecuteTime": {
     "end_time": "2024-02-14T06:27:47.170856800Z",
     "start_time": "2024-02-14T06:27:40.977233300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nityjZ5340wY",
    "ExecuteTime": {
     "end_time": "2024-02-14T06:27:50.162789300Z",
     "start_time": "2024-02-14T06:27:50.054296200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "dfnew=pd.read_csv('file1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ndKq429eFTYy",
    "ExecuteTime": {
     "end_time": "2024-02-14T06:31:23.556348300Z",
     "start_time": "2024-02-14T06:27:54.233492600Z"
    }
   },
   "outputs": [],
   "source": [
    "dfnew['image'] = dfnew['path'].map(lambda x: np.asarray(Image.open(x).resize((450,600))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "19reQa-KMD1G",
    "ExecuteTime": {
     "end_time": "2024-02-14T06:31:33.459878Z",
     "start_time": "2024-02-14T06:31:33.410636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, lesion_id, image_id, dx, dx_type, age, sex, localization, path, cell_type, cell_type_idx, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(dfnew['path'].isna().sum())  # Check for NaN values\n",
    "print(dfnew[dfnew['path'].apply(lambda x: not isinstance(x, str))])  # Check for non-string values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6FAaHtuWKB9"
   },
   "source": [
    "**2nd** **TIME**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KRtlL8czlizF",
    "ExecuteTime": {
     "end_time": "2024-02-14T06:31:47.950729900Z",
     "start_time": "2024-02-14T06:31:44.054099100Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WQjLdGOQ4-h_",
    "ExecuteTime": {
     "end_time": "2024-02-14T06:32:00.189183900Z",
     "start_time": "2024-02-14T06:32:00.161495200Z"
    }
   },
   "outputs": [],
   "source": [
    "df=dfnew\n",
    "features=df.drop(columns=['cell_type_idx'],axis=1)\n",
    "target=df['cell_type_idx']"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0    lesion_id      image_id     dx    dx_type   age      sex  \\\n",
      "3544        4583  HAM_0001668  ISIC_0027434     nv  follow_up  40.0   female   \n",
      "6099        7956  HAM_0001801  ISIC_0033293     nv      histo  35.0   female   \n",
      "3018        3867  HAM_0000608  ISIC_0025756     nv  follow_up  30.0   female   \n",
      "7357        9599  HAM_0005257  ISIC_0033751     nv  consensus   NaN  unknown   \n",
      "2931        3734  HAM_0007441  ISIC_0024548     nv  follow_up  60.0     male   \n",
      "...          ...          ...           ...    ...        ...   ...      ...   \n",
      "2878        3666  HAM_0001544  ISIC_0030875     nv  follow_up  50.0   female   \n",
      "1950        2442  HAM_0004769  ISIC_0025250   vasc  consensus  30.0     male   \n",
      "7597        9938  HAM_0007047  ISIC_0025957  akiec      histo  60.0   female   \n",
      "1922        2407  HAM_0003480  ISIC_0033844   vasc  consensus  70.0   female   \n",
      "6380        8336  HAM_0000025  ISIC_0024349     nv      histo  35.0     male   \n",
      "\n",
      "         localization                            path          cell_type  \\\n",
      "3544            trunk  melanoma\\both\\ISIC_0027434.jpg   Melanocytic nevi   \n",
      "6099          abdomen  melanoma\\both\\ISIC_0033293.jpg   Melanocytic nevi   \n",
      "3018             foot  melanoma\\both\\ISIC_0025756.jpg   Melanocytic nevi   \n",
      "7357          unknown  melanoma\\both\\ISIC_0033751.jpg   Melanocytic nevi   \n",
      "2931            trunk  melanoma\\both\\ISIC_0024548.jpg   Melanocytic nevi   \n",
      "...               ...                             ...                ...   \n",
      "2878             back  melanoma\\both\\ISIC_0030875.jpg   Melanocytic nevi   \n",
      "1950            scalp  melanoma\\both\\ISIC_0025250.jpg   Vascular lesions   \n",
      "7597  lower extremity  melanoma\\both\\ISIC_0025957.jpg  Actinic keratoses   \n",
      "1922  lower extremity  melanoma\\both\\ISIC_0033844.jpg   Vascular lesions   \n",
      "6380  lower extremity  melanoma\\both\\ISIC_0024349.jpg   Melanocytic nevi   \n",
      "\n",
      "                                                  image  \n",
      "3544  [[[229, 154, 161], [226, 155, 158], [229, 158,...  \n",
      "6099  [[[205, 182, 184], [202, 180, 181], [196, 183,...  \n",
      "3018  [[[206, 135, 139], [208, 138, 138], [205, 134,...  \n",
      "7357  [[[177, 163, 187], [179, 161, 188], [180, 160,...  \n",
      "2931  [[[212, 133, 153], [214, 134, 151], [214, 134,...  \n",
      "...                                                 ...  \n",
      "2878  [[[246, 167, 172], [248, 169, 171], [246, 169,...  \n",
      "1950  [[[178, 119, 140], [178, 119, 143], [177, 120,...  \n",
      "7597  [[[206, 155, 156], [206, 156, 157], [208, 158,...  \n",
      "1922  [[[92, 68, 81], [98, 75, 88], [102, 79, 90], [...  \n",
      "6380  [[[178, 144, 165], [179, 141, 165], [178, 136,...  \n",
      "\n",
      "[5742 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.25,random_state=666)\n",
    "tf.unique(x_train_o.cell_type.values)\n",
    "print(x_train_o)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T06:35:05.328777700Z",
     "start_time": "2024-02-14T06:34:55.670970700Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAWAT4\\AppData\\Local\\Temp\\ipykernel_18616\\2578750665.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  x_train = (x_train - x_train_mean) / x_train_std\n",
      "C:\\Users\\PRAWAT4\\AppData\\Local\\Temp\\ipykernel_18616\\2578750665.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  x_test = (x_test - x_test_mean) / x_test_std\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def convert_string_to_array(str_array):\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(str_array), dtype=np.float32)\n",
    "    except:\n",
    "        return np.zeros((1, 1, 3))\n",
    "\n",
    "x_train = np.array([convert_string_to_array(img_str) for img_str in x_train_o['image'].tolist()])\n",
    "x_test = np.array([convert_string_to_array(img_str) for img_str in x_test_o['image'].tolist()])\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_test_mean) / x_test_std\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T08:42:20.980954100Z",
     "start_time": "2024-02-14T08:42:15.588422200Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train_o, num_classes = 7)\n",
    "y_test = to_categorical(y_test_o, num_classes = 7)\n",
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T08:42:21.043605Z",
     "start_time": "2024-02-14T08:42:20.988586500Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 15501 into shape (5167,224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m x_train, x_validate, y_train, y_validate \u001B[38;5;241m=\u001B[39m train_test_split(x_train, y_train, test_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m, random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m999\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Reshape image in 3 dimensions (height = 100, width = 125 , canal = 3)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m x_train \u001B[38;5;241m=\u001B[39m \u001B[43mx_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m x_test \u001B[38;5;241m=\u001B[39m x_test\u001B[38;5;241m.\u001B[39mreshape(x_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m      5\u001B[0m x_validate \u001B[38;5;241m=\u001B[39m x_validate\u001B[38;5;241m.\u001B[39mreshape(x_validate\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 15501 into shape (5167,224,224,3)"
     ]
    }
   ],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 999)\n",
    "# Reshape image in 3 dimensions (height = 100, width = 125 , canal = 3)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(224, 224, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(224, 224, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(224, 224, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T08:42:21.164644900Z",
     "start_time": "2024-02-14T08:42:21.035888300Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the lengths of x_train and y_train are the same\n",
    "if len(x_train) != len(y_train):\n",
    "    raise ValueError(\"The number of images and labels must be the same.\")\n",
    "\n",
    "# Resize images to 224x224\n",
    "x_train_resized = np.array([cv2.resize(img, (224, 224)) for img in x_train])\n",
    "x_train = x_train_resized.reshape(-1, 224, 224, 3)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.1, random_state=999)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding) if necessary\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_validate = to_categorical(y_validate, num_classes)\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_validate:\", x_validate.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_validate:\", y_validate.shape)\n",
    "\n",
    "# Your model code goes here\n",
    "# ...\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-14T08:42:21.166053900Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load your dataset here\n",
    "# Example (replace this with your actual data loading code)\n",
    "# x_train = [load_your_images_here]  # This should be a list/array of images\n",
    "# y_train = [load_your_labels_here]  # This should be a list/array of labels\n",
    "\n",
    "# Ensure the lengths of x_train and y_train are the same\n",
    "if len(x_train) != len(y_train):\n",
    "    raise ValueError(\"The number of images and labels must be the same.\")\n",
    "\n",
    "# Resize images to 224x224\n",
    "x_train_resized = np.array([cv2.resize(img, (224, 224)) for img in x_train])\n",
    "x_train = x_train_resized.reshape(-1, 224, 224, 3)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.1, random_state=999)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding) if necessary\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_validate = to_categorical(y_validate, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:05:53.491968700Z",
     "start_time": "2024-02-14T07:04:27.209879200Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "WARNING:tensorflow:From C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n"
     ]
    }
   ],
   "source": [
    "mobile = tensorflow.keras.applications.mobilenet.MobileNet()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:06:46.652550400Z",
     "start_time": "2024-02-14T07:06:44.597392Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D  (None, 112, 112, 32)      288       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormali  (None, 112, 112, 32)      128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormali  (None, 112, 112, 64)      256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D  (None, 56, 56, 64)        576       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormali  (None, 56, 56, 64)        256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D  (None, 56, 56, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D  (None, 28, 28, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormali  (None, 28, 28, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D  (None, 28, 28, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D  (None, 14, 14, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormali  (None, 14, 14, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D  (None, 15, 15, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2  (None, 7, 7, 512)         4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormal  (None, 7, 7, 512)         2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2  (None, 7, 7, 1024)        9216      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1, 1, 1024)        0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_preds (Conv2D)         (None, 1, 1, 1000)        1025000   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1000)              0         \n",
      "                                                                 \n",
      " predictions (Activation)    (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4253864 (16.23 MB)\n",
      "Trainable params: 4231976 (16.14 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:07:39.503706300Z",
     "start_time": "2024-02-14T07:07:39.148618100Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not transfer weights for layer mobilenet_1.00_224\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 125, 3)]     0         \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functi  (None, 1000)              4253864   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4253864 (16.23 MB)\n",
      "Trainable params: 4231976 (16.14 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def change_model(model, new_input_shape=(None, 40, 40, 3), custom_objects=None):\n",
    "    # Create a new model with the new input shape\n",
    "    new_input = tf.keras.Input(shape=new_input_shape[1:])\n",
    "    output = model(new_input)\n",
    "\n",
    "    new_model = tf.keras.Model(inputs=new_input, outputs=output)\n",
    "\n",
    "    # Copy weights from the old model to the new one\n",
    "    for layer in new_model.layers:\n",
    "        if 'input' not in layer.name:\n",
    "            try:\n",
    "                old_layer = model.get_layer(name=layer.name)\n",
    "                layer.set_weights(old_layer.get_weights())\n",
    "                print(\"Loaded layer {layer}\".format(layer.name))\n",
    "            except:\n",
    "                print(\"Could not transfer weights for layer {layer}\".format(layer.name))\n",
    "\n",
    "    return new_model\n",
    "\n",
    "# Adjust the input shape as per your requirement\n",
    "new_model = change_model(mobile, new_input_shape=(None, 100, 125, 3))\n",
    "new_model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:08:34.274593700Z",
     "start_time": "2024-02-14T07:08:33.997116100Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dense, Dropout\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Connect the input layer to the new model\n",
    "x = new_model(input_layer)\n",
    "\n",
    "# Create a new dense layer for predictions\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "# Continue with the rest of your code"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:09:47.021075800Z",
     "start_time": "2024-02-14T07:09:46.780725100Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:10:36.462678100Z",
     "start_time": "2024-02-14T07:10:36.445282700Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:11:24.023846100Z",
     "start_time": "2024-02-14T07:11:24.011756700Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(Adam(learning_rate=0.01), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:13:02.929564800Z",
     "start_time": "2024-02-14T07:13:02.900095500Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # akiec\n",
    "    1: 1.0, # bcc\n",
    "    2: 1.0, # bkl\n",
    "    3: 1.0, # df\n",
    "    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n",
    "    5: 1.0, # nv\n",
    "    6: 1.0, # vasc\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:13:50.768039300Z",
     "start_time": "2024-02-14T07:13:50.763216Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/remove_squeezable_dimensions/Squeeze defined at (most recent call last):\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Temp\\ipykernel_18616\\1697941567.py\", line 27, in <module>\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2913, in fit_generator\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\losses.py\", line 263, in call\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\losses_utils.py\", line 200, in squeeze_or_expand_dimensions\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\losses_utils.py\", line 139, in remove_squeezable_dimensions\n\nCan not squeeze dim[2], expected a dimension of 1, got 2\n\t [[{{node categorical_crossentropy/remove_squeezable_dimensions/Squeeze}}]] [Op:__inference_train_function_12707]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 27\u001B[0m\n\u001B[0;32m     21\u001B[0m reduce_lr \u001B[38;5;241m=\u001B[39m ReduceLROnPlateau(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_top_3_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, \n\u001B[0;32m     22\u001B[0m                                    verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m, min_lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00001\u001B[39m)\n\u001B[0;32m     25\u001B[0m callbacks_list \u001B[38;5;241m=\u001B[39m [checkpoint, reduce_lr]\n\u001B[1;32m---> 27\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatagen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_validate\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_validate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\pythonprojectharsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/remove_squeezable_dimensions/Squeeze defined at (most recent call last):\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n\n  File \"C:\\Users\\PRAWAT4\\AppData\\Local\\Temp\\ipykernel_18616\\1697941567.py\", line 27, in <module>\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2913, in fit_generator\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\losses.py\", line 263, in call\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\losses_utils.py\", line 200, in squeeze_or_expand_dimensions\n\n  File \"C:\\pythonprojectharsh\\venv\\lib\\site-packages\\keras\\src\\utils\\losses_utils.py\", line 139, in remove_squeezable_dimensions\n\nCan not squeeze dim[2], expected a dimension of 1, got 2\n\t [[{{node categorical_crossentropy/remove_squeezable_dimensions/Squeeze}}]] [Op:__inference_train_function_12707]"
     ]
    }
   ],
   "source": [
    "from keras.src.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 16\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.12,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.12,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  \n",
    "\n",
    "filepath = \"model2.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(datagen.flow(x_train,y_train, batch_size=batch_size), \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=(x_validate,y_validate),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=10, verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T07:25:43.818527800Z",
     "start_time": "2024-02-14T07:25:30.570514600Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('model2.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNtTtVjJJJsIn3uHbfBkwSA",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1j0HPevcaiJMEf4mt6EjuNy7mqmbZcpjx",
   "name": "OSAMAH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
